{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Building a english to french translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tutorial:\n",
    "## https://medium.com/@dev.elect.iitd/neural-machine-translation-using-word-level-seq2seq-model-47538cba8cd7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hear argument morning case number brnovich ver...</td>\n",
       "      <td>mr chief justice may please court think key co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr carvin understand test articulate reduce an...</td>\n",
       "      <td>entirely mr chief justice reason involve diffe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talk concern analysis would drive racial propo...</td>\n",
       "      <td>well mean neutral system must change order max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really maximize participation equalize word co...</td>\n",
       "      <td>well example would eliminate valuable antifrau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thank mr chief justice mr carvin understand ra...</td>\n",
       "      <td>well justice thomas think speak precisely term...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>guess i'm i'm ask second time around way word ...</td>\n",
       "      <td>example tell independent review do context dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>good morning general wall i'm go let talk meri...</td>\n",
       "      <td>well look founding think vattel quote good thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>undocumented person country say year know even...</td>\n",
       "      <td>take long-term embassy personnel somebody who'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>mr palmore regardless whether zero understand ...</td>\n",
       "      <td>take long-term embassy personnel somebody who'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>concede illegal alien never exclude category c...</td>\n",
       "      <td>well yes take account alienage certain way yes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 action  \\\n",
       "0     hear argument morning case number brnovich ver...   \n",
       "1     mr carvin understand test articulate reduce an...   \n",
       "2     talk concern analysis would drive racial propo...   \n",
       "3     really maximize participation equalize word co...   \n",
       "4     thank mr chief justice mr carvin understand ra...   \n",
       "...                                                 ...   \n",
       "1995  guess i'm i'm ask second time around way word ...   \n",
       "1996  good morning general wall i'm go let talk meri...   \n",
       "1997  undocumented person country say year know even...   \n",
       "1998  mr palmore regardless whether zero understand ...   \n",
       "1999  concede illegal alien never exclude category c...   \n",
       "\n",
       "                                                  state  \n",
       "0     mr chief justice may please court think key co...  \n",
       "1     entirely mr chief justice reason involve diffe...  \n",
       "2     well mean neutral system must change order max...  \n",
       "3     well example would eliminate valuable antifrau...  \n",
       "4     well justice thomas think speak precisely term...  \n",
       "...                                                 ...  \n",
       "1995  example tell independent review do context dir...  \n",
       "1996  well look founding think vattel quote good thi...  \n",
       "1997  take long-term embassy personnel somebody who'...  \n",
       "1998  take long-term embassy personnel somebody who'...  \n",
       "1999  well yes take account alienage certain way yes...  \n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('action_state_text.csv', index_col=0)\n",
    "df = df.iloc[:2000,:]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_action_words=set()\n",
    "for a in df.action:\n",
    "    for word in a.split():\n",
    "        if word not in all_action_words:\n",
    "            all_action_words.add(word)\n",
    "    \n",
    "all_state_words=set()\n",
    "for s in df.state:\n",
    "    for word in s.split():\n",
    "        if word not in all_state_words:\n",
    "            all_state_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4835, 6522)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_action_words), len(all_state_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in df.state:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "np.max(lenght_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenght_list=[]\n",
    "for l in df.action:\n",
    "    lenght_list.append(len(l.split(' ')))\n",
    "np.max(lenght_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_words = sorted(list(all_state_words))\n",
    "target_words = sorted(list(all_action_words))\n",
    "num_encoder_tokens = len(all_state_words)\n",
    "num_decoder_tokens = len(all_action_words)\n",
    "# del all_eng_words, all_french_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict(\n",
    "    [(word, i) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(df.state), 577),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(df.action), 217),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(df.action), 217, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(df.state, df.action)):\n",
    "    for t, word in enumerate(input_text.split()):\n",
    "        encoder_input_data[i, t] = input_token_index[word]\n",
    "    for t, word in enumerate(target_text.split()):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t] = target_token_index[word]\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[word]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 577) (2000, 217) (2000, 217, 4835)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data.shape, decoder_input_data.shape, decoder_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "en_x=  Embedding(num_encoder_tokens, embedding_size)(encoder_inputs)\n",
    "encoder = LSTM(50, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(en_x)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dex=  Embedding(num_decoder_tokens, embedding_size)\n",
    "final_dex= dex(decoder_inputs)\n",
    "decoder_lstm = LSTM(50, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(final_dex,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 50)     326100      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 50)     241750      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50), (None,  20200       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 50), ( 20200       embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 4835)   246585      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 854,835\n",
      "Trainable params: 854,835\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15/15 [==============================] - 92s 6s/step - loss: 1.0768 - acc: 0.0013 - val_loss: 1.0314 - val_acc: 0.0014\n",
      "Epoch 2/20\n",
      "15/15 [==============================] - 99s 7s/step - loss: 0.9790 - acc: 0.0015 - val_loss: 0.9832 - val_acc: 0.0014\n",
      "Epoch 3/20\n",
      "15/15 [==============================] - 95s 6s/step - loss: 0.9451 - acc: 0.0015 - val_loss: 0.9708 - val_acc: 0.0014\n",
      "Epoch 4/20\n",
      "15/15 [==============================] - 101s 7s/step - loss: 0.9346 - acc: 0.0024 - val_loss: 0.9703 - val_acc: 0.0031\n",
      "Epoch 5/20\n",
      "15/15 [==============================] - 92s 6s/step - loss: 0.9319 - acc: 0.0027 - val_loss: 0.9730 - val_acc: 0.0031\n",
      "Epoch 6/20\n",
      "15/15 [==============================] - 90s 6s/step - loss: 0.9312 - acc: 0.0027 - val_loss: 0.9754 - val_acc: 0.0031\n",
      "Epoch 7/20\n",
      "15/15 [==============================] - 93s 6s/step - loss: 0.9306 - acc: 0.0027 - val_loss: 0.9771 - val_acc: 0.0031\n",
      "Epoch 8/20\n",
      "15/15 [==============================] - 91s 6s/step - loss: 0.9295 - acc: 0.0027 - val_loss: 0.9786 - val_acc: 0.0031\n",
      "Epoch 9/20\n",
      "15/15 [==============================] - 87s 6s/step - loss: 0.9281 - acc: 0.0027 - val_loss: 0.9797 - val_acc: 0.0031\n",
      "Epoch 10/20\n",
      "15/15 [==============================] - 91s 6s/step - loss: 0.9265 - acc: 0.0027 - val_loss: 0.9808 - val_acc: 0.0031\n",
      "Epoch 11/20\n",
      "15/15 [==============================] - 90s 6s/step - loss: 0.9249 - acc: 0.0027 - val_loss: 0.9831 - val_acc: 0.0031\n",
      "Epoch 12/20\n",
      "15/15 [==============================] - 111s 7s/step - loss: 0.9231 - acc: 0.0027 - val_loss: 0.9832 - val_acc: 0.0031\n",
      "Epoch 13/20\n",
      "15/15 [==============================] - 102s 7s/step - loss: 0.9210 - acc: 0.0027 - val_loss: 0.9847 - val_acc: 0.0031\n",
      "Epoch 14/20\n",
      "15/15 [==============================] - 118s 8s/step - loss: 0.9191 - acc: 0.0027 - val_loss: 0.9854 - val_acc: 0.0031\n",
      "Epoch 15/20\n",
      "15/15 [==============================] - 144s 10s/step - loss: 0.9171 - acc: 0.0027 - val_loss: 0.9862 - val_acc: 0.0031\n",
      "Epoch 16/20\n",
      "15/15 [==============================] - 130s 9s/step - loss: 0.9153 - acc: 0.0027 - val_loss: 0.9861 - val_acc: 0.0031\n",
      "Epoch 17/20\n",
      "15/15 [==============================] - 138s 9s/step - loss: 0.9135 - acc: 0.0027 - val_loss: 0.9870 - val_acc: 0.0031\n",
      "Epoch 18/20\n",
      "15/15 [==============================] - 119s 8s/step - loss: 0.9118 - acc: 0.0027 - val_loss: 0.9867 - val_acc: 0.0032\n",
      "Epoch 19/20\n",
      "15/15 [==============================] - 152s 10s/step - loss: 0.9101 - acc: 0.0027 - val_loss: 0.9877 - val_acc: 0.0029\n",
      "Epoch 20/20\n",
      "15/15 [==============================] - 176s 12s/step - loss: 0.9086 - acc: 0.0029 - val_loss: 0.9883 - val_acc: 0.0033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13db38820>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 50)          326100    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 50), (None, 50),  20200     \n",
      "=================================================================\n",
      "Total params: 346,300\n",
      "Trainable params: 346,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(50,))\n",
    "decoder_state_input_c = Input(shape=(50,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "final_dex2= dex(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(final_dex2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "#     target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 52):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------\n",
      "Input sentence: [\"think mean court meant crawford understand usual burden voting make good point know need benchmark usual burden otherwise meant congress invalidate virtually every time place manner restriction need safe harbor point we're making section immunize minority usual burden voting say show right precinct sort thing there's nothing language section somehow exempt long roughly commensurate normal election day system exist would constitute usual burden voting\"]\n",
      "Decoded sentence:  question question question question question question\n",
      "------------------\n",
      "Input sentence: ['would say equally open mean take account demographic reality one polling place five people one polling place million people obviously latter situation people equal opportunity vote']\n",
      "Decoded sentence:  question question question question question question\n",
      "------------------\n",
      "Input sentence: [\"well sort discretion say that's standard feature fee-shifting statute mean fee-shifting statute mean section good example section say fee reasonable\"]\n",
      "Decoded sentence:  question question question question question question\n",
      "------------------\n",
      "Input sentence: [\"yes honor that's one line draw three simply put case government request receive b dismissal court even need reach second\"]\n",
      "Decoded sentence:  question question question question question question\n",
      "------------------\n",
      "Input sentence: [\"well course justice kagan court matter avoidance severability merit think normally court would theory inseverability weak usually hard overcome presumption severability claim would go motion dismiss stage see claim think problem side drive home justice alito's hypothetical think side say even statute express inseverability provision obvious constitutional problem like racial discrimination obvious statute legal nullity everyone regulate statute challenge somebody come along racially discriminate article iii stand matter seem right we're\"]\n",
      "Decoded sentence:  question question question question question question\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [10,15,200,254,780]:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('------------------')\n",
    "    print('Input sentence:', df.state[seq_index: seq_index + 1].values)\n",
    "    print('Decoded sentence:', decoded_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/zhiyulin/opt/anaconda3/envs/anly580/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/zhiyulin/opt/anaconda3/envs/anly580/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: seq2seq_wordlevel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"seq2seq_wordlevel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('seq2seq_wordlevel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anly580",
   "language": "python",
   "name": "anly580"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
